{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chinmaya54/DM_Challenge_WC_Winner/blob/Asish/Data_Mining_Playing11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLgxeDmOPBBr",
        "outputId": "1130961a-b23a-4c95-9420-df70436f2377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.3333333333333333\n",
            "Predicted Playing 11:\n",
            "                 Player  Role\n",
            "9        Jasprit Bumrah     3\n",
            "11       Mohammed Shami     3\n",
            "0          Rohit Sharma     1\n",
            "12       Mohammed Siraj     3\n",
            "5          Ishan Kishan     1\n",
            "8        Shardul Thakur     3\n",
            "2           Virat Kohli     1\n",
            "1         Shubhman Gill     1\n",
            "13  Ravichandran Ashwin     3\n",
            "4              KL Rahul     1\n",
            "7       Ravindra Jadeja     2\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = {\n",
        "    'Player': ['Rohit Sharma', 'Shubhman Gill', 'Virat Kohli', 'Shreyas Iyer', 'KL Rahul',\n",
        "               'Ishan Kishan', 'Suryakumar Yadav', 'Ravindra Jadeja', 'Shardul Thakur',\n",
        "               'Jasprit Bumrah', 'Kuldeep Yadav', 'Mohammed Shami', 'Mohammed Siraj',\n",
        "               'Ravichandran Ashwin'],\n",
        "    'Runs': [10615, 2187, 13677, 2222, 2638, 933, 754, 2747, 329, 90, 99, 214, 39, 707],\n",
        "    'StrikeRate': [91.64, 103.06, 93.54, 99.42, 88.38, 102.19, 106.8, 85.36, 105.11, 87, 56.83, 83.92, 40.22, 86.96],\n",
        "    '100': [31, 6, 49, 4, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    '50': [55, 12, 71, 17, 16, 7, 4, 13, 1, 0, 0, 0, 0, 1],\n",
        "    'Economy': [5.24, 5.5, 6.16, 6.32, 0, 0, 0, 4.88, 6.23, 4.57, 5.04, 5.55, 4.96, 4.93],\n",
        "    'Wickets': [9, 0, 5, 0, 0, 0, 0, 220, 65, 146, 166, 24.14, 66, 156],\n",
        "    'Matches': [260, 42, 290, 56, 70, 27, 35, 195, 47, 87, 99, 99, 39, 116],\n",
        "    'Average': [49.14, 60.75, 58.45, 49.38, 49.77, 42.14, 26.93, 32.7, 17.32, 8.18, 10.53, 7.93, 6.17, 16.44],\n",
        "    'Role': ['Bat', 'Bat', 'Bat', 'Bat', 'Bat', 'Bat', 'Bat', 'All', 'Bowl', 'Bowl', 'Bowl', 'Bowl', 'Bowl', 'Bowl']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Map roles to numerical values\n",
        "role_mapping = {'Bat': 1, 'All': 2, 'Bowl': 3}\n",
        "df['Role'] = df['Role'].map(role_mapping)\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Runs', 'StrikeRate', '100', '50', 'Economy', 'Wickets', 'Matches', 'Average']\n",
        "target = 'Role'\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Model Accuracy: {accuracy}')\n",
        "\n",
        "# Predict the playing 11\n",
        "playing_11 = df[df['Role'].isin([1, 2, 3])].sample(n=11, random_state=42)\n",
        "print('Predicted Playing 11:')\n",
        "print(playing_11[['Player', 'Role']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.impute import SimpleImputer  # Importing imputer to handle missing values\n",
        "\n",
        "# Load the dataset\n",
        "data = {\n",
        "    'Player': ['Rohit Sharma', 'Shubhman Gill', 'Virat Kohli', 'Shreyas Iyer', 'KL Rahul',\n",
        "               'Ishan Kishan', 'Suryakumar Yadav', 'Ravindra Jadeja', 'Shardul Thakur',\n",
        "               'Jasprit Bumrah', 'Kuldeep Yadav', 'Mohammed Shami', 'Mohammed Siraj',\n",
        "               'Ravichandran Ashwin'],\n",
        "    'Runs': [10615, 2187, 13677, 2222, 2638, 933, 754, 2747, 329, 90, 99, 214, 39, 707],\n",
        "    'StrikeRate': [91.64, 103.06, 93.54, 99.42, 88.38, 102.19, 106.8, 85.36, 105.11, 87, 56.83, 83.92, 40.22, 86.96],\n",
        "    '100': [31, 6, 49, 4, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    '50': [55, 12, 71, 17, 16, 7, 4, 13, 1, 0, 0, 0, 0, 1],\n",
        "    'Economy': [5.24, 5.5, 6.16, 6.32, 0, 0, 0, 4.88, 6.23, 4.57, 5.04, 5.55, 4.96, 4.93],\n",
        "    'Wickets': [9, 0, 5, 0, 0, 0, 0, 220, 65, 146, 166, 24.14, 66, 156],\n",
        "    'Matches': [260, 42, 290, 56, 70, 27, 35, 195, 47, 87, 99, 99, 39, 116],\n",
        "    'Average': [49.14, 60.75, 58.45, 49.38, 49.77, 42.14, 26.93, 32.7, 17.32, 8.18, 10.53, 7.93, 6.17, 16.44],\n",
        "    'Role': ['Bat', 'Bat', 'Bat', 'Bat', 'Bat', 'Bat', 'Bat', 'All', 'Bowl', 'Bowl', 'Bowl', 'Bowl', 'Bowl', 'Bowl']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Map roles to numerical values\n",
        "role_mapping = {'Bat': 1, 'All': 2, 'Bowl': 3}\n",
        "df['Role'] = df['Role'].map(role_mapping)\n",
        "\n",
        "# Check for missing values in the target variable\n",
        "if df['Role'].isnull().any():\n",
        "    # Handle missing values using imputation (replace NaN with the most frequent value)\n",
        "    imputer = SimpleImputer(strategy='most_frequent')\n",
        "    df['Role'] = imputer.fit_transform(df[['Role']])\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Runs', 'StrikeRate', '100', '50', 'Economy', 'Wickets', 'Matches', 'Average']\n",
        "target = 'Role'\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# List of classifiers\n",
        "classifiers = {\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"\\nTraining and evaluating {name}:\\n\")\n",
        "\n",
        "    # Train the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predictions = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    report = classification_report(y_test, predictions, target_names=role_mapping.keys())\n",
        "\n",
        "    print(f'Model Accuracy ({name}): {accuracy:.4f}')\n",
        "    print(f'Classification Report ({name}):\\n{report}')\n",
        "\n",
        "# Predict the playing 11 using the best-performing classifier (in this case, the Decision Tree)\n",
        "best_classifier = DecisionTreeClassifier(random_state=42)\n",
        "best_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the playing 11\n",
        "playing_11 = df[df['Role'].isin([1, 2, 3])].sample(n=11, random_state=42)\n",
        "playing_11['PredictedRole'] = best_classifier.predict(playing_11[features])\n",
        "\n",
        "# Print the predicted players\n",
        "print('\\nPredicted Playing 11:')\n",
        "for role in ['Bat', 'All', 'Bowl']:\n",
        "    role_players = playing_11[playing_11['PredictedRole'] == role]\n",
        "    print(f'\\n{role} Players:')\n",
        "    print(role_players[['Player', 'Role']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "45YswvvbQbla",
        "outputId": "cbb16a25-8894-48e0-be99-ed27cac0c292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and evaluating Decision Tree:\n",
            "\n",
            "Model Accuracy (Decision Tree): 0.3333\n",
            "Classification Report (Decision Tree):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bat       0.50      1.00      0.67         1\n",
            "         All       0.00      0.00      0.00         0\n",
            "        Bowl       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.33      0.22         3\n",
            "weighted avg       0.17      0.33      0.22         3\n",
            "\n",
            "\n",
            "Training and evaluating Random Forest:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c24ef511a872>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model Accuracy ({name}): {accuracy:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2330\u001b[0m             )\n\u001b[1;32m   2331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2333\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 2, does not match size of target_names, 3. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"/content/squad.csv\")  # Replace \"your_dataset.csv\" with your actual CSV file path\n"
      ],
      "metadata": {
        "id": "SfX3G8y-RujQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Handle missing values in the target variable ('Role')\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "df['Role'] = imputer.fit_transform(df[['Role']])\n"
      ],
      "metadata": {
        "id": "XxoWhrxrR17d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Runs', 'Strike Rate', '100', '50', 'Economy', 'wickets', 'Matches', 'Average']\n",
        "target = 'Role'\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "dt_predictions = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "dt_report = classification_report(y_test, dt_predictions, target_names=df['Role'].unique())\n",
        "\n",
        "print(f'Decision Tree Accuracy: {dt_accuracy:.4f}')\n",
        "print(f'Decision Tree Classification Report:\\n{dt_report}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTV67g_7R700",
        "outputId": "bc9f535e-2d2e-48a9-ff65-689e4cf46355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.3333\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bat       0.00      0.00      0.00         0\n",
            "         All       0.50      1.00      0.67         1\n",
            "        Bowl       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.33      0.22         3\n",
            "weighted avg       0.17      0.33      0.22         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Random Forest\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "rf_report = classification_report(y_test, rf_predictions, labels=df['Role'].unique(), target_names=df['Role'].unique())\n",
        "\n",
        "print(f'Random Forest Accuracy: {rf_accuracy:.4f}')\n",
        "print(f'Random Forest Classification Report:\\n{rf_report}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C32cmsP7SIph",
        "outputId": "aeaf26c9-76aa-452d-8d15-9c87626846f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 1.0000\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bat       1.00      1.00      1.00         1\n",
            "         All       0.00      0.00      0.00         0\n",
            "        Bowl       1.00      1.00      1.00         2\n",
            "\n",
            "   micro avg       1.00      1.00      1.00         3\n",
            "   macro avg       0.67      0.67      0.67         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/squad.csv\")  # Replace \"your_dataset.csv\" with your actual CSV file path\n",
        "\n",
        "# Check and handle missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "df['Role'] = imputer.fit_transform(df[['Role']])\n"
      ],
      "metadata": {
        "id": "EAjVW9o9SxxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Runs', 'Strike Rate', '100', '50', 'Economy', 'wickets', 'Matches', 'Average']\n",
        "target = 'Role'\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "dt_predictions = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "print(f'Decision Tree Accuracy: {dt_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMDjGCh2VafG",
        "outputId": "390d5cd8-8fe4-430f-a697-abaeb9f6738c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Random Forest\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f'Random Forest Accuracy: {rf_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-HkLU8xVfBA",
        "outputId": "896c977a-304a-45ee-f203-8f6810ba6003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train SVM\n",
        "svm_classifier = SVC(random_state=42)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(f'SVM Accuracy: {svm_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtB3RO6_VirA",
        "outputId": "516f53b1-64d1-4aa8-c915-ec5326c496bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Train KNN\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "knn_predictions = knn_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(f'KNN Accuracy: {knn_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU-TrYCuVmxO",
        "outputId": "78fb3ded-fec6-4a3c-abea-f1938f07ae9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the playing 11\n",
        "predicted_roles = best_classifier.predict(df[features])\n",
        "df['PredictedRole'] = predicted_roles\n",
        "\n",
        "# Sort players based on predicted roles and other relevant criteria\n",
        "sorted_players = df.sort_values(by=['PredictedRole', 'Runs', 'wickets'], ascending=[True, False, False])\n",
        "\n",
        "# Select players for each role\n",
        "bat_players = sorted_players[sorted_players['Role'] == 'Bat'][:6]\n",
        "all_rounder = sorted_players[sorted_players['Role'] == 'All'][:1]\n",
        "bowl_players = sorted_players[sorted_players['Role'] == 'Bowl'][:4]\n",
        "\n",
        "# Concatenate selected players\n",
        "selected_players = pd.concat([bat_players, all_rounder, bowl_players])\n",
        "\n",
        "# Print the predicted players\n",
        "print('\\nPredicted Playing 11:')\n",
        "for role in ['Bat', 'All', 'Bowl']:\n",
        "    role_players = selected_players[selected_players['Role'] == role]\n",
        "    print(f'\\n{role} Players:')\n",
        "    print(role_players[['Player', 'Role']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAgQGEGEVqeZ",
        "outputId": "904e0b7b-041f-47cf-effb-3201c6b9f83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Playing 11:\n",
            "\n",
            "Bat Players:\n",
            "          Player Role\n",
            "2    Virat Kohli  Bat\n",
            "0   Rohit sharma  Bat\n",
            "4       KL Rahul  Bat\n",
            "3   Shreyas Iyer  Bat\n",
            "1  Shubhman Gill  Bat\n",
            "5   Ishan kishan  Bat\n",
            "\n",
            "All Players:\n",
            "            Player Role\n",
            "7  Ravindra Jadeja  All\n",
            "\n",
            "Bowl Players:\n",
            "                 Player  Role\n",
            "13  Ravichandran Ashwin  Bowl\n",
            "8        Shardul Thakur  Bowl\n",
            "11        Mohmmed Shami  Bowl\n",
            "10        Kuldeep Yadav  Bowl\n"
          ]
        }
      ]
    }
  ]
}